---
title: "R Code Chunks"
author: "Adam Lineberry"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

### Insert today's date in RMarkdown date field

```{r}
date: "`r format(Sys.time(), '%d %B, %Y')`"
```

### Check count of NA's in each column of dataframe

```{r}
colSums(is.na(weather_raw))
```

### delete or clear global environment

```{r}
remove(list=ls())
```


### Load data into R, download data if not already present

```{r}
fileName <- "filename.csv"
if (!file.exists(fileName)){
  url <- "https://file.csv"
  download.file(url = url, destfile = fileName)
}
x <- read.csv(fileName)
```

### Multiple files, download if not present, assign to data frames
```{r}
url <- c("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
         "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
filename <- c("pml-training.csv", "pml-testing.csv")

datafiles <- list(c(url[1],filename[1]),c(url[2],filename[2]))

getData <- function(inp){
    url <- inp[1]; fileName <- inp[2]
    if (!file.exists(fileName)){
      download.file(url = url, destfile = fileName)
    }
    x <- read.csv(fileName); x
}

data <- lapply(datafiles, getData)
train <- data[[1]]; test <- data[[2]]
```


### View rendered html file stored on github

http://htmlpreview.github.com/github_url_to_htmlfile_here

### Converting data from long to wide format

```{r}
library(reshape2); library(datasets); data(ChickWeight)
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, 
                value.var="weight")
```

### histogram with ggplot

```{r}
library(ggplot2)
g = ggplot(data.frame(medians=medians), aes(x=medians))
g = g + geom_histogram(color="black", fill="lightblue", binwidth=0.05)
g
```

### panel plots with ggplot (45 degree lables)

```{r}
library(ggplot2); library(gridExtra)
figf<-ggplot(ford,aes(x=EVTYPE1,y=FATALITIES))+
        geom_bar(stat="identity",fill="red",width=.6)+
        theme(axis.text.x=element_text(face="plain", 
                                       color="black",size=8,
                                       angle=45,hjust=1),
              plot.title=element_text(size=11),
              axis.title=element_text(size=9))+
        scale_x_discrete(limits=ford$EVTYPE1[1:10])+
        labs(x="",y="",title="Fatalities")
figi <- ...
figp <- ...
figc <- ...
grid.arrange(figf,figi,figp,figc,ncol = 2)
```

### bar chart, ggplot2, horizontal bars, values at ends of bars

```{r}
ggplot(data = fat.data, aes(x=reorder(EVTYPE,+Fat), y = Fat)) +
    geom_col() + coord_flip() + xlab("") + theme_minimal() +
    scale_y_continuous(name = "Fatalities", breaks=seq(0,6000,1000), limits=c(0, 6100)) + 
    geom_text(aes(label=Fat), hjust=-0.2, vjust=0.5, color="black", size=3.5) +
    ggtitle("Top 10 Weather Events by Human Fatality")
```


### use dplyr to group by and summarize / aggregate data

```{r}
dmg <- x %>% group_by(EVTYPE) %>% 
           summarize(Eco.Dmg = sum(PROPDMG, na.rm = TRUE) + 
                         sum(CROPDMG, na.rm = TRUE),
                     Inj = sum(INJURIES, na.rm = TRUE),
                     Fat = sum(FATALITIES, na.rm = TRUE))
```


### use ggplot to plot histogram with normal distribution overlay

```{r}
bw <- 0.05
means.plot2 = ggplot(data.frame(sample.means=means.sim), aes(x=sample.means))
means.plot2 = means.plot2 + geom_histogram(color="lightblue", fill="lightblue" , binwidth=bw) + xlab("") +
    stat_function(fun=function(x, mean, sd, n, bw){ 
                     dnorm(x = x, mean = mean, sd = sd) * n * bw
    }, 
    args = c(mean = mean(means.sim), sd = sd(means.sim), n = 1000, bw = bw),
    size = 1) +
    ggtitle("Distribution of Sample Means with Normal Distribution Overlay")
```


### loading multiple packages at once

```{r}
pkg <- c("dplyr", "ggplot2", "gridExtra", "knitr")
sapply(pkg, require, character.only = TRUE)
```


### control scientific notation

```{r}
options(scipen=999)
```


### logical bin width for ggplot histograms

```{r}
bw = (range(tg$len)[2] - range(tg$len)[1]) / nrow(tg)
bw = bw * 1.5
```


### initialize an empty data frame with column names

```{r}
results <- data.frame(CI.LB = numeric(0), CI.UB = numeric(0),
                      p.value = numeric(0))
```

### pairs plot with ggplot

```{r}
require(datasets); data(swiss); require(GGally); require(ggplot2)
g = ggpairs(swiss, lower = list(continuous = "smooth"),
            params = c(method = "loess")); g 
```

### feature correlations: heatmaps and list of highest correlations

```{r}
heatmap(cor(train[-53]), symm=TRUE)

melt_cor <- melt(cor(train[-53]))
melt_cor$value <- abs(melt_cor$value)
melt_cor <- melt_cor[order(melt_cor$value, decreasing=TRUE),]
melt_cor <- melt_cor[melt_cor$value != 1,]
kable(head(melt_cor,10))

cor_hmap <- ggplot(data=melt_cor, aes(x=Var1, y=Var2, fill=value)) + geom_tile()
cor_hmap <- cor_hmap + theme(axis.text.x = element_text(angle = 90))
cor_hmap
```

### plot heat map of missing data

```{r}
library(Amelia)
missmap(training.data.raw, main = "Missing values vs observed")
```

### heatmap with dendrogram and clustering turned off

```{r}
nba_heatmap <- heatmap(nba_matrix, Rowv=NA, Colv=NA, col = cm.colors(256), scale="column", margins=c(5,10))
```

### covert date to julian day

```{r}
julian(date)
```

### melt data frame using melt()

```{r}
p <- 0:100 / 100
odds <- p / (1-p)
dat <- data.frame(cbind(p,odds))
dat$logit <- log(odds)
library(reshape2)
melt(dat, id.vars=p)
```

### using cut2() to make factors from a continuous variable

```{r}
library(Hmisc)
cutWage <- cut2(training$wage, g = 3)
```
- Cuts wage into 3 chunks based on quantile group (should be equally sized groups)
- factor levels (ie names) show the chunk quantiles

